<!doctype html><html lang=en-us><head><head><br><br><title>Combining Slurm and GNU parallel</title><style>html body{font-family:,sans-serif;background-color:#fff}:root{--accent: #2196F3;--border-width:  0 }</style><link rel=stylesheet href=../../../css/main.css><link rel=stylesheet href=../../../css/perso.css><link rel=stylesheet href=../../../css/family.css><link rel=stylesheet href=../../../css/creativecommons.css><link href=https://unpkg.com/ionicons@4.2.2/dist/css/ionicons.min.css rel=stylesheet><link rel=stylesheet href=../../../css/font-awesome.min.css><link rel=stylesheet href=../../../css/academicons.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script src=../../../js/jquery-ui-1.9.1.custom.min.js></script><script src=../../../js/jquery.tocify.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//bash.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//julia.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//python.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//rust.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//xml.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//yaml.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//tex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//shell.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/languages//matlab.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/styles/tomorrow-night-eighties.min.css><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: false,
    }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/latest.js?config=TeX-MML-AM_CHTML" async></script><link rel=stylesheet href=https://unpkg.com/leaflet@1.5.1/dist/leaflet.css integrity="sha512-xwE/Az9zrjBIphAcBb3F6JVqxf46+CDLwfLMHloNu6KEQCAWi6HcDUbeOfBIptF7tcCzusKFjFw2yuvEpDL9wQ==" crossorigin><script src=https://unpkg.com/leaflet@1.5.1/dist/leaflet.js integrity="sha512-GffPMF3RvMeYyc1LWMHtK8EbPv0iNZ8/oTtHPx9/cc2ILxQ+u905qIwdpULaqDkyBKgOaB57QTMg7ztg8Jm2Og==" crossorigin></script><meta name=generator content="Hugo 0.57.2"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"></head></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#bs-example-navbar-collapse-1>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button></div><div class="collapse navbar-collapse" id=bs-example-navbar-collapse-1><ul class="nav navbar-nav mr-auto"><li><a href=../../../publications/>Publications</a></li><li><a href=../../../talks/>Talks&amp;Posters</a></li><li><a href=../../../teaching/>Teaching</a></li><li><a href=../../../software/>Software</a></li><li><a href=../../../econotes/>EcoNotes</a></li><li><a href=../../../notes/>SilicoNotes</a></li><li><a href=../../../perso/>Perso</a></li></ul><ul class="nav navbar-nav navbar-right"><li class=navbar-icon><a href=../../../><i class="fa fa-home"></i></a></li><li class=navbar-icon><a href=https://insileco.github.io/><i class="fa fa-external-link-square"></i></a></li><li class=navbar-icon><a href=https://github.com/KevCaz/KevCaz.github.io><i class="fa fa-github"></i></a></li></ul></ul></div></div></nav><br><div class=container><div class=row><div class=col-sm-2><div class="hidden-sm hidden-xs"></div></div><div class=col-sm-10><div class=article-meta><h1><span class=title>Combining Slurm and GNU parallel</span></h1><h3><span class=subtitle></span></h3><h3 class=date style=font-size:1.25em>November 11, 2019</h2><p class=tags><i class="fa fa-tags" aria-hidden=true></i>&nbsp;
<a href=../../../tags/compute-canada><kbd class=item-tag>Compute Canada</kbd></a>
<a href=../../../tags/advances-research-computing><kbd class=item-tag>Advances Research Computing</kbd></a>
<a href=../../../tags/high-performance-computing><kbd class=item-tag>High Performance Computing</kbd></a>
<a href=../../../tags/gnu-parallel><kbd class=item-tag>GNU parallel</kbd></a>
<a href=../../../tags/slurm><kbd class=item-tag>Slurm</kbd></a></p><br></div><p>Last week, I attended a &ldquo;Midi conf√©rence&rdquo; (basically a one hour training session
during lunch time) offered by Compute Canada dealing with
<a href=https://slurm.schedmd.com/quickstart.html target=_blank>Slurm</a>, <a href=https://www.gnu.org/software/parallel/ target=_blank>GNU
Parallel</a> and how to combine them. This
was a very useful and timely presentation for me (<a href="https://docs.google.com/presentation/d/1ysIaSWa157yiZ-ocX1jkAys1NkGgwolArSwCgAYCUPQ/edit?ts=5dc04169#slide=id.g65b5e056e3_0_5" target=_blank>üá´üá∑ slides available online
üîó</a>)
as I&rsquo;ve just got started with Slurm (see my <a href=../../../notes/computesci/graham>previous notes on the
topic</a>) and was eager to learn more.</p><p>Earlier today, I found an opportunity to put in practice what I&rsquo;ve learned last
week. Indeed I needed to download hundreds of shapefiles (2 different kind of
shapefiles at 2 different for almost 120 years), extract values from them before
deleting them. To do so, I wrote the following bash script to distribute the
simulations on 5 nodes and use 4 CPUs per node:</p><pre><code class=language-shell>#!/bin/bash
#SBATCH --time=6:00:00
#SBATCH --nodes=5
#SBATCH --array=1-5
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=4G
#SBATCH --account=def-ksmccann
#SBATCH --mail-user=kcazelle@uoguelph.ca
#SBATCH --mail-type=FAIL

# working directory is where the task is submitted
cd $SLURM_SUBMIT_DIR

parallel --delay 1 Rscript ./scr_extract.R $SLURM_ARRAY_TASK_ID {1} {2} ::: {1..2} ::: {1..2}
</code></pre><p>The <code>#SBATCH</code> instructions do the following:</p><ul><li><code>#SBATCH --time=6:00:00</code>: allocate 6 hours for the job;</li><li><code>#SBATCH --nodes=5</code>: allocate 5 nodes;</li><li><code>#SBATCH --array=1-5</code>: generate 5 tasks with 1, 2, 3, 4 and 5 as identifiers (represented by <code>$SLURM_ARRAY_TASK_ID</code>);</li><li><code>#SBATCH --ntasks-per-node=1</code>: only one task per node;</li><li><code>#SBATCH --cpus-per-task=4</code>: allocate 4 CPUs per task;</li><li><code>#SBATCH --mem-per-cpu=4G</code>: allocate 4Gb of RAM per CPU.</li></ul><p>and in the main command:</p><pre><code>$ parallel --delay 1 Rscript ./scr_extract.R $SLURM_ARRAY_TASK_ID {1} {2} ::: {1..2} ::: {1..2}
</code></pre><p>the Rscript <code>scr_extract.R</code> takes 3 arguments:</p><ul><li>the first one are the task identifiers (<code>$SLURM_ARRAY_TASK_ID</code>) managed by
Slurm and, given the setup I described above, this argument varies with the
node!</li><li>the second and third arguments are handled by GNU parallel so that, on each node, it generates the same four combinations (i.e. (1,1), (1,2), (2,1), (2,2)), each of which is run by one of the four CPUs alloacated per node.</li></ul><p>‚ö†Ô∏è Note that if <code>SBATCH --ntasks-per-node=1</code> is used without specifying
the number of CPUs per task, only one CPU will be allocated, making <code>parallel</code>
useless! That is why I added <code>#SBATCH --cpus-per-task=4</code> to have 4 instead of 1.</p><p>So, this set up allowed me to</p><ol><li>use five different nodes and to have a unique ID for those (<code>$SLURM_ARRAY_TASK_ID</code>);</li><li>do the same parallelization on each of them (with a different input).</li></ol><p>It turned out the only good reason for doing that was to apply what I&rsquo;ve learned
a few days ago üòÜüòÜüòÜ!</p></div></div></div><br><br><footer><div class=row><div class=col-sm-3><div class="hidden-sm hidden-xs"></div></div><div class=col-sm-8><div class=row><hr><div class=col-sm-10 style=text-align:center>Personnal website built with <i class="icon ion-md-heart"></i>, <a href=https://gohugo.io/>Hugo</a>
and my <a href=https://github.com/KevCaz/hugo-KevCaz>own theme</a>!
<i class="fa fa-code" aria-hidden=true></i>available on
<a href=https://github.com/KevCaz/KevCaz.github.io><i class="fa fa-github" aria-hidden></i></a>.<br>All content is licensed under
<a href=https://creativecommons.org/licenses/by-nc-sa/4.0/><i class="cc cc-cc-circle cc-1x"></i><i class="cc cc-by-circle cc-1x"></i><i class="cc cc-nc-circle cc-1x"></i><i class="cc cc-sa-circle cc-1x"></i></a>unless otherwise specified.</div><div class=col-sm-2><a href=#><i class="fa fa-arrow-circle-o-up fa-2x" aria-hidden=true></i></a><br><br></div><div></div></div><br></footer></body></html>